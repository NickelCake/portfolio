<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GovernAIce — Nicole Lee</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=DM+Serif+Display:ital@0;1&family=IBM+Plex+Sans:wght@300;400;500;600&display=swap" rel="stylesheet">
    <style>
        :root {
            --color-bg: #fafaf9;
            --color-text: #1a1816;
            --color-text-muted: #6b6662;
            --color-accent: #d97706;
            --color-accent-dark: #b45309;
            --color-border: #e7e5e4;
            --color-surface: #ffffff;
            
            --font-display: 'DM Serif Display', serif;
            --font-body: 'IBM Plex Sans', system-ui, sans-serif;
            
            --spacing-xs: 0.5rem;
            --spacing-sm: 1rem;
            --spacing-md: 2rem;
            --spacing-lg: 4rem;
            --spacing-xl: 6rem;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html {
            font-size: 16px;
            scroll-behavior: smooth;
        }

        body {
            font-family: var(--font-body);
            font-weight: 400;
            line-height: 1.7;
            color: var(--color-text);
            background: var(--color-bg);
            -webkit-font-smoothing: antialiased;
            -moz-osx-font-smoothing: grayscale;
        }

        h1, h2, h3, h4, h5, h6 {
            font-family: var(--font-display);
            font-weight: 400;
            line-height: 1.2;
            color: var(--color-text);
        }

        strong {
            font-weight: 600;
        }

        .container {
            max-width: 1100px;
            margin: 0 auto;
            padding: 0 var(--spacing-md);
        }

        /* Navigation */
        nav {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            background: rgba(250, 250, 249, 0.95);
            backdrop-filter: blur(12px);
            border-bottom: 1px solid var(--color-border);
            z-index: 1000;
            padding: var(--spacing-md) 0;
        }

        nav .container {
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .nav-logo {
            font-family: var(--font-display);
            font-size: 1.25rem;
            color: var(--color-text);
            text-decoration: none;
            font-style: italic;
            transition: color 0.3s ease;
        }

        .nav-logo:hover {
            color: var(--color-accent);
        }

        .nav-links {
            display: flex;
            gap: var(--spacing-md);
            list-style: none;
        }

        .nav-links a {
            color: var(--color-text-muted);
            text-decoration: none;
            font-size: 0.95rem;
            font-weight: 500;
            transition: color 0.3s ease;
        }

        .nav-links a:hover {
            color: var(--color-text);
        }

        .back-link {
            color: var(--color-accent-dark);
            text-decoration: none;
            font-weight: 500;
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            margin-bottom: var(--spacing-md);
            transition: color 0.3s ease;
        }

        .back-link:hover {
            color: var(--color-accent);
        }

        /* Project Page Styles */
        .project-page {
            padding: calc(var(--spacing-xl) + 80px) 0 var(--spacing-xl);
        }

        .project-header {
            background: var(--color-surface);
            padding: 3rem 3rem 2rem;
            border-bottom: 1px solid var(--color-border);
            margin-bottom: 0;
        }

        .project-header h1 {
            font-size: 3rem;
            margin-bottom: 1rem;
            font-style: italic;
        }

        .project-overview {
            font-size: 1.25rem;
            color: var(--color-text-muted);
            margin-bottom: 2rem;
            line-height: 1.6;
        }

        .project-meta-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 1.5rem;
        }

        .meta-item {
            display: flex;
            flex-direction: column;
            gap: 0.25rem;
        }

        .meta-label {
            font-size: 0.85rem;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            color: var(--color-text-muted);
            font-weight: 600;
        }

        .meta-value {
            font-size: 1rem;
            color: var(--color-text);
        }

        .project-body {
            background: var(--color-surface);
            padding: 3rem;
        }

        .content-section {
            margin-bottom: 3rem;
        }

        .content-section:last-child {
            margin-bottom: 0;
        }

        .content-section h3 {
            font-size: 1.75rem;
            margin-bottom: 1.5rem;
            font-style: italic;
        }

        .content-section h4 {
            font-size: 1.25rem;
            margin-bottom: 1rem;
            margin-top: 2rem;
        }

        .content-section p {
            font-size: 1.05rem;
            margin-bottom: 1.25rem;
            line-height: 1.7;
        }

        .content-section ul {
            list-style: none;
            margin-bottom: 1.5rem;
        }

        .content-section li {
            font-size: 1.05rem;
            padding-left: 1.5rem;
            margin-bottom: 0.75rem;
            position: relative;
            line-height: 1.6;
        }

        .content-section li::before {
            content: '→';
            position: absolute;
            left: 0;
            color: var(--color-accent);
        }

        .highlight-box {
            background: var(--color-bg);
            border-left: 4px solid var(--color-accent);
            padding: 1.5rem;
            margin: 2rem 0;
        }

        .highlight-box p {
            margin-bottom: 0;
            font-style: italic;
            color: var(--color-text-muted);
        }

        /* Footer */
        footer {
            border-top: 1px solid var(--color-border);
            padding: var(--spacing-lg) 0;
            text-align: center;
            background: var(--color-bg);
        }

        footer p {
            color: var(--color-text-muted);
            font-size: 0.9rem;
        }

        /* Responsive */
        @media (max-width: 768px) {
            nav .container {
                flex-direction: column;
                gap: var(--spacing-sm);
                align-items: flex-start;
            }

            .nav-links {
                gap: var(--spacing-sm);
            }

            .project-page {
                padding: calc(var(--spacing-lg) + 120px) 0 var(--spacing-lg);
            }

            .project-header {
                padding: 2rem 1.5rem 1.5rem;
            }

            .project-header h1 {
                font-size: 2rem;
            }

            .project-body {
                padding: 1.5rem;
            }
        }
    </style>
</head>
<body>
    <nav>
        <div class="container">
            <a href="nicole-lee-portfolio.html" class="nav-logo">Nicole Lee</a>
            <ul class="nav-links">
                <li><a href="nicole-lee-portfolio.html#work">Work</a></li>
                <li><a href="nicole-lee-portfolio.html#about">About</a></li>
                <li><a href="nicole-lee-portfolio.html#contact">Contact</a></li>
            </ul>
        </div>
    </nav>

    <main class="project-page">
        <div class="container">
            <a href="nicole-lee-portfolio.html#work" class="back-link">← Back to Work</a>
            
            <div class="project-header">
                <h1>GovernAIce</h1>
                <p class="project-overview">Building trust in AI governance systems through transparency</p>
                <div class="project-meta-grid">
                    <div class="meta-item">
                        <div class="meta-label">My Role</div>
                        <div class="meta-value">UX Research, Service Design</div>
                    </div>
                    <div class="meta-item">
                        <div class="meta-label">Timeline</div>
                        <div class="meta-value">16 weeks</div>
                    </div>
                    <div class="meta-item">
                        <div class="meta-label">Tools</div>
                        <div class="meta-value">Figma, Stakeholder Interviews, Journey Mapping</div>
                    </div>
                </div>
            </div>
            
            <div class="project-body">
                <div class="content-section">
                    <h3>1. Problem / Challenge</h3>
                    <p>GovernAIce is a platform that helps organizations govern their AI systems—ensuring models are fair, compliant, and operating as intended. As AI becomes critical to business decisions, companies need visibility into how these systems work and confidence that they're behaving appropriately.</p>
                    <p>The users were AI governance teams, compliance officers, and executives at enterprises deploying AI at scale. These stakeholders needed to audit AI decision-making, ensure regulatory compliance, and manage risk across dozens or hundreds of AI models.</p>
                    <p>The core problem: Organizations lacked visibility into AI decision-making processes, creating trust issues both internally (teams couldn't validate that models worked as expected) and externally (companies couldn't demonstrate compliance to regulators or explain decisions to customers). The platform had technical monitoring capabilities but didn't make governance actionable—users got data but didn't know what to do with it.</p>
                </div>

                <div class="content-section">
                    <h3>2. Role & Responsibilities</h3>
                    <p><strong>My role:</strong> I led UX research and service design, working with a product team and AI ethics advisors. I conducted stakeholder interviews across different organizational roles, mapped end-to-end governance workflows, designed interface concepts for transparency features, and created journey maps that identified gaps in the current experience.</p>
                    <p><strong>Timeline:</strong> 16 weeks from initial research through validated design concepts</p>
                    <p><strong>Tools:</strong> Figma for interface design, stakeholder interviews and workshops, journey mapping to understand cross-functional workflows, collaborative design sessions with compliance experts</p>
                </div>

                <div class="content-section">
                    <h3>3. Research & Insights</h3>
                    <p>I conducted 18 stakeholder interviews across different roles (AI governance leads, compliance officers, data scientists, executives) to understand the full governance ecosystem. I also ran workshops with cross-functional teams to map their actual governance processes and pain points.</p>
                    <h4>Key Insights</h4>
                    <ul>
                        <li><strong>Invisible decision chains:</strong> When an AI model made a decision (like denying a loan application), stakeholders couldn't trace why. The system showed metrics like "accuracy: 94%" but not "this person was denied because X, Y, Z factors"</li>
                        <li><strong>Reactive, not proactive:</strong> Teams only investigated models when something went wrong. They lacked tools to proactively identify issues like bias or drift before they caused harm</li>
                        <li><strong>Communication breakdown:</strong> Different stakeholders needed different views of the same information. Data scientists needed technical metrics while compliance officers needed regulatory language. There was no shared understanding across teams</li>
                    </ul>
                    <div class="highlight-box">
                        <p>"We have all this monitoring data, but when an executive asks 'can we trust this model?' I don't have a clear answer. I can show them numbers, but numbers don't build trust without context." — Interview participant, AI governance lead at financial services company</p>
                    </div>
                </div>

                <div class="content-section">
                    <h3>4. Design Goals / Constraints</h3>
                    <p>The main design goals were:</p>
                    <ul>
                        <li>Make AI decision-making transparent and traceable—show not just what a model decided, but why</li>
                        <li>Enable proactive governance—surface potential issues before they become problems</li>
                        <li>Create a shared language across technical and non-technical stakeholders so everyone can understand model behavior</li>
                    </ul>
                    <p><strong>Constraints:</strong> We were operating in a complex regulatory environment where compliance requirements were still evolving—we had to design for flexibility. The technical challenge was significant: explaining ML decisions in plain language without oversimplifying to the point of inaccuracy. We also had to balance transparency with intellectual property concerns (companies didn't want to expose proprietary model details). Different industries had different needs, so the solution needed to be adaptable across healthcare, finance, and other sectors.</p>
                </div>

                <div class="content-section">
                    <h3>5. Ideation & Iteration</h3>
                    <p>I started by mapping the current governance workflow end-to-end, identifying where different stakeholders interacted with the system. My first concept was a comprehensive dashboard showing all model metrics in one view. Testing with compliance officers revealed this was overwhelming—they needed focused views for specific governance tasks, not a "kitchen sink" dashboard.</p>
                    <p><strong>Iteration 1:</strong> I designed role-specific views—one for data scientists, another for compliance, another for executives. Users appreciated seeing relevant information, but this created siloed understanding. When teams needed to collaborate on an issue, they were literally looking at different systems.</p>
                    <p><strong>Key learning:</strong> We needed shared visibility with role-specific actions, not completely separate interfaces.</p>
                    <p><strong>Iteration 2:</strong> I created a layered transparency model. The core view showed model behavior in plain language anyone could understand (e.g., "This model denied 45 applications this week. Top reasons: credit score too low (60%), insufficient income (25%), employment history (15%)"). Each stakeholder could then "drill down" into their relevant details—data scientists could see technical metrics, compliance could see regulatory mappings, executives could see business impact.</p>
                    <p><strong>Specific design decision:</strong> We introduced "decision explanations" that traced individual AI decisions through a visual flow. For example, if reviewing a denied loan, users could see: "Applicant data → Model considered 23 factors → Primary decision drivers: income-to-debt ratio and credit history → Result: Application denied." This gave teams a shared understanding while allowing technical deep-dives when needed. We tested this with mixed stakeholder groups and found it enabled productive conversations between technical and non-technical teams for the first time.</p>
                </div>

                <div class="content-section">
                    <h3>6. Final Solution</h3>
                    <p>The redesigned governance platform makes AI decision-making visible and actionable:</p>
                    <ul>
                        <li><strong>Transparent decision tracking</strong> — For any AI decision, users can trace the reasoning from input through model logic to outcome, explained in plain language with technical details available on demand</li>
                        <li><strong>Proactive issue detection</strong> — Automated monitoring surfaces potential bias, performance drift, and compliance risks before they cause harm, with clear alerts and recommended actions</li>
                        <li><strong>Cross-functional communication</strong> — A shared view of model behavior that different stakeholders can interpret through their lens (technical, regulatory, business) creates alignment across teams</li>
                    </ul>
                    <div class="highlight-box">
                        <p>How it solves the original problem: Organizations can now confidently answer "how does this AI system work?" and "can we trust it?" The platform transforms technical monitoring data into governance insights that different stakeholders can understand and act on. Trust is built through visibility, not just metrics.</p>
                    </div>
                </div>

                <div class="content-section">
                    <h3>7. Outcomes / Learnings</h3>
                    <p><strong>Impact:</strong> During pilot testing, compliance officers reported 60% reduction in time spent investigating model decisions. Cross-functional teams could now have productive governance discussions without getting stuck on translation between technical and business language. Executives reported increased confidence in AI deployments—one said "for the first time I can actually explain to the board how we're governing AI."</p>
                    <p><strong>What I'd measure next:</strong> I'd track issue detection rate (are we catching problems earlier?) and resolution time (how quickly can teams respond to governance issues?). Would also measure cross-functional collaboration quality through team surveys and meeting outcomes. Long-term, would track whether better governance visibility correlates with reduced AI incidents and improved regulatory compliance.</p>
                    <p><strong>What I learned:</strong> Transparency isn't about showing everything—it's about showing the right thing to the right person at the right time. Service design requires understanding not just individual user needs but the ecosystem of interactions between different roles. Also, trust in complex systems comes from understanding, not just performance metrics. You can't design trust into an interface, but you can design experiences that enable people to develop trust through visibility and control.</p>
                </div>
            </div>
        </div>
    </main>

    <footer>
        <div class="container">
            <p>© 2025 Nicole Lee — Designed & built with care</p>
        </div>
    </footer>
</body>
</html>
